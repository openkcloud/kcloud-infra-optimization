#!/usr/bin/env python3
"""
kcloud-opt ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
PostgreSQL + TimescaleDB + Redisë¥¼ í™œìš©í•œ ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ì†”ë£¨ì…˜
"""

import sys
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager

# ê²½ë¡œ ì„¤ì •
sys.path.insert(0, '/root/kcloud_opt')

# í†µí•© ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
from infrastructure.database.connection import get_database_manager, init_database, close_database
from infrastructure.monitoring.enhanced_metrics_collector import EnhancedMetricsCollector, EnhancedClusterMetrics
from infrastructure.monitoring.enhanced_alert_system import EnhancedAlertSystem, EnhancedAlert
from infrastructure.database.redis_keys import RedisKeys, RedisPubSubChannels, RedisDataTypes

# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ (í´ë°±ìš©)
from infrastructure.monitoring.realtime_dashboard import RealTimeDashboard
from infrastructure.monitoring.integrated_monitor import IntegratedMonitor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseIntegratedMonitor:
    """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, update_interval: int = 30, use_database: bool = True):
        self.update_interval = update_interval
        self.use_database = use_database
        self.running = False
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.db_manager = None
        self.metrics_collector = None
        self.alert_system = None
        self.dashboard = None
        
        # í´ë°± ì‹œìŠ¤í…œ (DB ì—°ê²° ì‹¤íŒ¨ ì‹œ)
        self.fallback_monitor = None
        
        # ìƒíƒœ ê´€ë¦¬
        self.last_health_check = None
        self.error_count = 0
        self.max_errors = 5
    
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
            
            if self.use_database:
                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„
                await self._initialize_database_components()
            else:
                # í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ì´ˆê¸°í™”
                await self._initialize_fallback_system()
            
            logger.info("âœ… ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            if self.use_database:
                logger.info("ğŸ”„ í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜")
                await self._initialize_fallback_system()
            else:
                raise
    
    async def _initialize_database_components(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.db_manager = await init_database()
            
            # í–¥ìƒëœ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.metrics_collector = EnhancedMetricsCollector(self.db_manager)
            self.alert_system = EnhancedAlertSystem(self.db_manager)
            await self.alert_system.initialize()
            
            # ëŒ€ì‹œë³´ë“œ (ê¸°ì¡´ ì‹œìŠ¤í…œ ì¬ì‚¬ìš©)
            self.dashboard = RealTimeDashboard(self.update_interval)
            
            logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì‹œìŠ¤í…œ í™œì„±í™”")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_fallback_system(self):
        """í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.fallback_monitor = IntegratedMonitor(self.update_interval)
            logger.info("ğŸ”„ í´ë°± ì‹œìŠ¤í…œ í™œì„±í™”")
        except Exception as e:
            logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def monitor_clusters_enhanced(self, cluster_names: List[str]) -> Dict[str, Any]:
        """í–¥ìƒëœ í´ëŸ¬ìŠ¤í„° ëª¨ë‹ˆí„°ë§"""
        if not self.use_database or not self.db_manager:
            return await self._monitor_clusters_fallback(cluster_names)
        
        try:
            logger.info(f"ğŸ” í–¥ìƒëœ ëª¨ë‹ˆí„°ë§: {len(cluster_names)}ê°œ í´ëŸ¬ìŠ¤í„°")
            
            # ë¹„ë™ê¸° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics_list = await self.metrics_collector.collect_multiple_clusters_async(cluster_names)
            
            # ì•Œë¦¼ ì²˜ë¦¬
            all_alerts = []
            for metrics in metrics_list:
                alerts = await self.alert_system.process_metrics_alerts(metrics)
                all_alerts.extend(alerts)
            
            # ìš”ì•½ ìƒì„±
            summary = await self._generate_enhanced_summary(metrics_list, all_alerts)
            
            # ëŒ€ì‹œë³´ë“œ ìºì‹œ ì—…ë°ì´íŠ¸
            await self._update_dashboard_cache(summary)
            
            self.error_count = 0  # ì„±ê³µ ì‹œ ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            return summary
            
        except Exception as e:
            logger.error(f"í–¥ìƒëœ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            self.error_count += 1
            
            # ì—ëŸ¬ê°€ ë§ìœ¼ë©´ í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
            if self.error_count >= self.max_errors:
                logger.warning("ğŸ”„ ì—ëŸ¬ í•œê³„ ë„ë‹¬ - í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜")
                return await self._monitor_clusters_fallback(cluster_names)
            
            return await self._generate_error_summary(str(e))
    
    async def _monitor_clusters_fallback(self, cluster_names: List[str]) -> Dict[str, Any]:
        """í´ë°± ëª¨ë‹ˆí„°ë§"""
        if not self.fallback_monitor:
            await self._initialize_fallback_system()
        
        logger.info(f"ğŸ”„ í´ë°± ëª¨ë‹ˆí„°ë§: {len(cluster_names)}ê°œ í´ëŸ¬ìŠ¤í„°")
        cluster_metrics = self.fallback_monitor.monitor_clusters(cluster_names)
        
        # ê¸°ì¡´ í˜•ì‹ì„ ìƒˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
            'timestamp': datetime.now().isoformat(),
            'mode': 'fallback',
            'clusters': {name: metrics.to_dict() for name, metrics in cluster_metrics.items()},
            'summary': self._generate_basic_summary(cluster_metrics),
            'alerts': {'total_active': 0, 'recent_alerts': []},
            'recommendations': self._generate_basic_recommendations(cluster_metrics)
        }
    
    async def _generate_enhanced_summary(self, metrics_list: List[EnhancedClusterMetrics], 
                                       alerts: List[EnhancedAlert]) -> Dict[str, Any]:
        """í–¥ìƒëœ ìš”ì•½ ìƒì„±"""
        total_cost = sum(m.cost_per_hour for m in metrics_list)
        total_power = sum(m.power_consumption_watts for m in metrics_list)
        active_clusters = len([m for m in metrics_list if m.status == 'CREATE_COMPLETE'])
        
        # ì•Œë¦¼ ìš”ì•½
        alert_summary = await self.alert_system.get_alert_summary()
        
        # ì„±ëŠ¥ ë¶„ì„
        performance_analysis = await self._analyze_cluster_performance(metrics_list)
        
        return {
            'timestamp': datetime.now().isoformat(),
            'mode': 'database_integrated',
            'clusters': {m.cluster_name: m.to_db_dict() for m in metrics_list},
            'summary': {
                'total_cost_per_hour': total_cost,
                'total_power_consumption': total_power,
                'active_clusters': active_clusters,
                'total_clusters': len(metrics_list),
                'avg_health_score': sum(m.health_score for m in metrics_list if m.status == 'CREATE_COMPLETE') / max(active_clusters, 1),
                'avg_efficiency_score': sum(m.efficiency_score for m in metrics_list if m.status == 'CREATE_COMPLETE') / max(active_clusters, 1)
            },
            'alerts': alert_summary,
            'performance': performance_analysis,
            'recommendations': await self._generate_smart_recommendations(metrics_list, alerts),
            'database_stats': await self._get_database_stats()
        }
    
    async def _analyze_cluster_performance(self, metrics_list: List[EnhancedClusterMetrics]) -> Dict[str, Any]:
        """í´ëŸ¬ìŠ¤í„° ì„±ëŠ¥ ë¶„ì„"""
        active_metrics = [m for m in metrics_list if m.status == 'CREATE_COMPLETE']
        
        if not active_metrics:
            return {'status': 'no_active_clusters'}
        
        analysis = {
            'cpu': {
                'avg': sum(m.cpu_usage for m in active_metrics) / len(active_metrics),
                'max': max(m.cpu_usage for m in active_metrics),
                'min': min(m.cpu_usage for m in active_metrics)
            },
            'memory': {
                'avg': sum(m.memory_usage for m in active_metrics) / len(active_metrics),
                'max': max(m.memory_usage for m in active_metrics),
                'min': min(m.memory_usage for m in active_metrics)
            },
            'cost_efficiency': {
                'cost_per_performance': sum(m.cost_per_hour / max(m.efficiency_score, 1) for m in active_metrics) / len(active_metrics),
                'high_cost_clusters': [m.cluster_name for m in active_metrics if m.cost_per_hour > 10.0],
                'low_efficiency_clusters': [m.cluster_name for m in active_metrics if m.efficiency_score < 40.0]
            },
            'health_trends': {
                'healthy_clusters': len([m for m in active_metrics if m.health_score > 80]),
                'warning_clusters': len([m for m in active_metrics if 50 <= m.health_score <= 80]),
                'critical_clusters': len([m for m in active_metrics if m.health_score < 50])
            }
        }
        
        return analysis
    
    async def _generate_smart_recommendations(self, metrics_list: List[EnhancedClusterMetrics], 
                                            alerts: List[EnhancedAlert]) -> List[str]:
        """ìŠ¤ë§ˆíŠ¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        active_metrics = [m for m in metrics_list if m.status == 'CREATE_COMPLETE']
        
        if not active_metrics:
            return ["í˜„ì¬ í™œì„± í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤"]
        
        # ë¹„ìš© ë¶„ì„
        high_cost = [m for m in active_metrics if m.cost_per_hour > 15.0]
        if high_cost:
            total_potential_savings = sum(m.cost_per_hour * 0.3 for m in high_cost)
            recommendations.append(f"ê³ ë¹„ìš© í´ëŸ¬ìŠ¤í„° {len(high_cost)}ê°œ ìµœì í™”ë¡œ ì›” ${total_potential_savings * 24 * 30:.0f} ì ˆì•½ ê°€ëŠ¥")
        
        # ì„±ëŠ¥ ë¶„ì„
        low_cpu = [m for m in active_metrics if m.cpu_usage < 20.0]
        if len(low_cpu) > 1:
            recommendations.append(f"ì €í™œìš© í´ëŸ¬ìŠ¤í„° {len(low_cpu)}ê°œ í†µí•©ìœ¼ë¡œ ì¸í”„ë¼ ë¹„ìš© ì ˆì•½ ê²€í† ")
        
        # GPU ë¶„ì„
        gpu_clusters = [m for m in active_metrics if m.gpu_usage > 0]
        if gpu_clusters:
            avg_gpu = sum(m.gpu_usage for m in gpu_clusters) / len(gpu_clusters)
            if avg_gpu < 30:
                recommendations.append(f"GPU í™œìš©ë¥  {avg_gpu:.1f}% - GPU ë…¸ë“œ ìˆ˜ ì¡°ì • ê¶Œì¥")
        
        # ì•Œë¦¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        critical_alerts = [a for a in alerts if a.severity == 'CRITICAL']
        if critical_alerts:
            recommendations.append(f"ê¸´ê¸‰ ì•Œë¦¼ {len(critical_alerts)}ê°œ - ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”")
        
        # í—¬ìŠ¤ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        unhealthy = [m for m in active_metrics if m.health_score < 70]
        if unhealthy:
            recommendations.append(f"í—¬ìŠ¤ ë¬¸ì œ í´ëŸ¬ìŠ¤í„° {len(unhealthy)}ê°œ - ì¥ì•  ì˜ˆë°© ì ê²€ ê¶Œì¥")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ì–‘í˜¸ - ì •ê¸° ëª¨ë‹ˆí„°ë§ ìœ ì§€")
        
        return recommendations
    
    async def _get_database_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„"""
        if not self.db_manager or not self.db_manager.is_connected:
            return {'status': 'disconnected'}
        
        try:
            # PostgreSQL í†µê³„
            pg_stats = await self.db_manager.execute_query(
                """
                SELECT 
                    (SELECT count(*) FROM cluster_metrics WHERE time >= NOW() - INTERVAL '1 hour') as metrics_1h,
                    (SELECT count(*) FROM clusters) as total_clusters,
                    (SELECT count(*) FROM alerts WHERE triggered_at >= NOW() - INTERVAL '24 hours') as alerts_24h,
                    (SELECT pg_database_size(current_database())) as db_size_bytes
                """,
                fetch='one'
            )
            
            # Redis í†µê³„
            redis_info = await self.db_manager.redis_client.info()
            
            return {
                'status': 'connected',
                'postgresql': {
                    'metrics_last_hour': pg_stats['metrics_1h'],
                    'total_clusters': pg_stats['total_clusters'],
                    'alerts_24h': pg_stats['alerts_24h'],
                    'database_size_mb': round(pg_stats['db_size_bytes'] / 1024 / 1024, 2)
                },
                'redis': {
                    'memory_used_mb': round(redis_info['used_memory'] / 1024 / 1024, 2),
                    'keys_count': redis_info['db0']['keys'] if 'db0' in redis_info else 0,
                    'hit_rate': f"{redis_info.get('keyspace_hit_rate', 0):.2f}%"
                }
            }
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'status': 'error', 'message': str(e)}
    
    async def _update_dashboard_cache(self, summary: Dict[str, Any]):
        """ëŒ€ì‹œë³´ë“œ ìºì‹œ ì—…ë°ì´íŠ¸"""
        try:
            cache_data = RedisDataTypes.create_dashboard_cache(
                summary['clusters'],
                summary['summary'], 
                summary['alerts']['total_active']
            )
            
            await self.db_manager.redis_set(
                RedisKeys.dashboard_cache(),
                cache_data,
                RedisExpirePolicy.DASHBOARD_CACHE
            )
            
        except Exception as e:
            logger.error(f"ëŒ€ì‹œë³´ë“œ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def run_continuous_monitoring(self, cluster_names: List[str]):
        """ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        logger.info(f"ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        logger.info(f"ğŸ“Š ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ: {len(cluster_names)}ê°œ í´ëŸ¬ìŠ¤í„°")
        logger.info(f"â±ï¸  ì—…ë°ì´íŠ¸ ì£¼ê¸°: {self.update_interval}ì´ˆ")
        print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
        
        self.running = True
        
        try:
            while self.running:
                print(f"\n{'='*80}")
                print(f"â° ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                if self.use_database and self.db_manager:
                    print("ğŸ—„ï¸ ëª¨ë“œ: ë°ì´í„°ë² ì´ìŠ¤ í†µí•©")
                else:
                    print("ğŸ”„ ëª¨ë“œ: í´ë°± ì‹œìŠ¤í…œ")
                print('='*80)
                
                # ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
                summary = await self.monitor_clusters_enhanced(cluster_names)
                
                # ê²°ê³¼ ì¶œë ¥
                self._print_monitoring_summary(summary)
                
                # í—¬ìŠ¤ ì²´í¬
                if datetime.now() - (self.last_health_check or datetime.min) > timedelta(minutes=5):
                    await self._perform_health_check()
                
                # ë‹¤ìŒ ì—…ë°ì´íŠ¸ê¹Œì§€ ëŒ€ê¸°
                print(f"\nğŸ’¤ {self.update_interval}ì´ˆ í›„ ë‹¤ìŒ ì—…ë°ì´íŠ¸...")
                await asyncio.sleep(self.update_interval)
                
        except KeyboardInterrupt:
            print(f"\n\nğŸ‘‹ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
            self.running = False
        except Exception as e:
            print(f"\nâŒ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            logger.error(f"ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            self.running = False
    
    def _print_monitoring_summary(self, summary: Dict[str, Any]):
        """ëª¨ë‹ˆí„°ë§ ìš”ì•½ ì¶œë ¥"""
        if not summary.get('clusters'):
            print("âŒ ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ê¸°ë³¸ ì •ë³´
        summary_data = summary['summary']
        print(f"\nğŸ“¦ í´ëŸ¬ìŠ¤í„° ìƒíƒœ:")
        print(f"  í™œì„±: {summary_data['active_clusters']}/{summary_data['total_clusters']}ê°œ")
        print(f"  ğŸ’° ì´ ë¹„ìš©: ${summary_data['total_cost_per_hour']:.2f}/ì‹œê°„")
        print(f"  ğŸ“… ì˜ˆìƒ ì›”ë¹„ìš©: ${summary_data['total_cost_per_hour'] * 24 * 30:.0f}")
        print(f"  ğŸ”‹ ì´ ì „ë ¥: {summary_data['total_power_consumption']:.0f}W")
        
        if summary_data['active_clusters'] > 0:
            print(f"  ğŸ’š í‰ê·  í—¬ìŠ¤: {summary_data.get('avg_health_score', 0):.1f}/100")
            print(f"  âš¡ í‰ê·  íš¨ìœ¨ì„±: {summary_data.get('avg_efficiency_score', 0):.1f}/100")
        
        # ì•Œë¦¼ ì •ë³´
        alerts = summary['alerts']
        if alerts['total_active'] > 0:
            print(f"\nğŸš¨ í™œì„± ì•Œë¦¼: {alerts['total_active']}ê°œ")
            print(f"  CRITICAL: {alerts['by_severity']['CRITICAL']}ê°œ")
            print(f"  WARNING: {alerts['by_severity']['WARNING']}ê°œ")
            print(f"  INFO: {alerts['by_severity']['INFO']}ê°œ")
        else:
            print(f"\nâœ… í™œì„± ì•Œë¦¼ ì—†ìŒ")
        
        # ì„±ëŠ¥ ë¶„ì„ (í–¥ìƒëœ ëª¨ë“œë§Œ)
        if 'performance' in summary:
            perf = summary['performance']
            if 'cpu' in perf:
                print(f"\nğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
                print(f"  CPU í‰ê· : {perf['cpu']['avg']:.1f}% (ìµœëŒ€: {perf['cpu']['max']:.1f}%)")
                print(f"  ë©”ëª¨ë¦¬ í‰ê· : {perf['memory']['avg']:.1f}% (ìµœëŒ€: {perf['memory']['max']:.1f}%)")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ (í–¥ìƒëœ ëª¨ë“œë§Œ)
        if 'database_stats' in summary and summary['database_stats'].get('status') == 'connected':
            db_stats = summary['database_stats']
            print(f"\nğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤:")
            print(f"  ë©”íŠ¸ë¦­ (1ì‹œê°„): {db_stats['postgresql']['metrics_last_hour']}ê°œ")
            print(f"  Redis ë©”ëª¨ë¦¬: {db_stats['redis']['memory_used_mb']}MB")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = summary.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in recommendations[:3]:  # ìƒìœ„ 3ê°œë§Œ
                print(f"  - {rec}")
    
    async def _perform_health_check(self):
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
        try:
            if self.db_manager:
                health = await self.db_manager.health_check()
                if not health['postgres'] or not health['redis']:
                    logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ ì²´í¬ ê²½ê³ : {health}")
            
            self.last_health_check = datetime.now()
            
        except Exception as e:
            logger.error(f"í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
        self.running = False
        
        if self.db_manager:
            await close_database()
        
        logger.info("âœ… ì •ë¦¬ ì™„ë£Œ")
    
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ (ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜ì„±)
    def _generate_basic_summary(self, cluster_metrics: Dict) -> Dict[str, Any]:
        """ê¸°ë³¸ ìš”ì•½ ìƒì„± (í´ë°±ìš©)"""
        return {
            'total_cost_per_hour': sum(m.cost_per_hour for m in cluster_metrics.values()),
            'total_power_consumption': sum(m.power_consumption_watts for m in cluster_metrics.values()),
            'active_clusters': len([m for m in cluster_metrics.values() if m.status == 'CREATE_COMPLETE']),
            'total_clusters': len(cluster_metrics)
        }
    
    def _generate_basic_recommendations(self, cluster_metrics: Dict) -> List[str]:
        """ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ ìƒì„± (í´ë°±ìš©)"""
        active_metrics = [m for m in cluster_metrics.values() if m.status == 'CREATE_COMPLETE']
        
        if not active_metrics:
            return ["í˜„ì¬ í™œì„± í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤"]
        
        recommendations = []
        
        high_cost = [m for m in active_metrics if m.cost_per_hour > 10.0]
        if high_cost:
            recommendations.append(f"ë†’ì€ ë¹„ìš© í´ëŸ¬ìŠ¤í„° {len(high_cost)}ê°œ ìµœì í™” í•„ìš”")
        
        if not recommendations:
            recommendations.append("í˜„ì¬ ìµœì í™” ìƒíƒœ ì–‘í˜¸")
        
        return recommendations
    
    async def _generate_error_summary(self, error_msg: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ìš”ì•½ ìƒì„±"""
        return {
            'timestamp': datetime.now().isoformat(),
            'mode': 'error',
            'error': error_msg,
            'clusters': {},
            'summary': {
                'total_cost_per_hour': 0.0,
                'total_power_consumption': 0.0,
                'active_clusters': 0,
                'total_clusters': 0
            },
            'alerts': {'total_active': 0, 'recent_alerts': []},
            'recommendations': ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ëª¨ë‹ˆí„°ë§ ì¼ì‹œ ì¤‘ë‹¨"]
        }


# ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
@asynccontextmanager
async def database_monitoring_context(cluster_names: List[str], 
                                    update_interval: int = 30,
                                    use_database: bool = True):
    """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§ ì»¨í…ìŠ¤íŠ¸"""
    monitor = DatabaseIntegratedMonitor(update_interval, use_database)
    try:
        await monitor.initialize()
        yield monitor
    finally:
        await monitor.cleanup()


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='kcloud-opt ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§')
    parser.add_argument('--mode', choices=['continuous', 'once', 'test'], default='continuous')
    parser.add_argument('--interval', type=int, default=30, help='ì—…ë°ì´íŠ¸ ì£¼ê¸°(ì´ˆ)')
    parser.add_argument('--clusters', nargs='+', default=['kcloud-dev-cluster'])
    parser.add_argument('--no-database', action='store_true', help='ë°ì´í„°ë² ì´ìŠ¤ ì—†ì´ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    print("ğŸŒ kcloud-opt ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    use_database = not args.no_database
    
    async with database_monitoring_context(args.clusters, args.interval, use_database) as monitor:
        if args.mode == 'continuous':
            await monitor.run_continuous_monitoring(args.clusters)
        elif args.mode == 'once':
            summary = await monitor.monitor_clusters_enhanced(args.clusters)
            monitor._print_monitoring_summary(summary)
        elif args.mode == 'test':
            print("ğŸ§ª ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
            summary = await monitor.monitor_clusters_enhanced(args.clusters)
            print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(summary['clusters'])}ê°œ í´ëŸ¬ìŠ¤í„° ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")
            if monitor.db_manager:
                health = await monitor.db_manager.health_check()
                print(f"ğŸ¥ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ: {health}")


if __name__ == "__main__":
    asyncio.run(main())